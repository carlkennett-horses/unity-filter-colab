{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# \ud83c\udfc7 Unity Filter \u2014 ATR PDF \u2192 Top\u20112 per Race (Colab)\n\n**What this notebook does**\n1. Installs dependencies (Camelot, pandas).\n2. Lets you upload an ATR racecard PDF from your device.\n3. Parses the PDF into tables.\n4. Runs a deterministic Unity filter wrapper.\n5. Prints a clean Top\u20112 selections grid for each race.\n\n> Tip: If parsing finds 0 tables, switch `PARSING_FLAVOR` to `\"lattice\"` in the setup cell."
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": [],
      "source": "# === Step 1: Install dependencies (run once per session) ===\n!apt-get -y install ghostscript > /dev/null\n!pip -q install pandas camelot-py[cv] pdfplumber tabula-py > /dev/null\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Switch between 'stream' (text-based tables) and 'lattice' (gridlines).\nPARSING_FLAVOR = \"stream\"  # change to \"lattice\" if 0 tables found"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upload"
      },
      "execution_count": null,
      "outputs": [],
      "source": "# === Step 2: Upload your ATR PDF ===\nfrom google.colab import files\nuploaded = files.upload()\n\npdf_path = next(iter(uploaded.keys()))\nprint(\"Uploaded:\", pdf_path)"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "parse"
      },
      "execution_count": null,
      "outputs": [],
      "source": "# === Step 3: Parse the PDF into tables ===\nimport camelot\nimport pandas as pd\n\ndef parse_pdf_tables(path, flavor=\"stream\"):\n    try:\n        tables = camelot.read_pdf(path, pages=\"all\", flavor=flavor)\n        print(f\"[Camelot] Found {len(tables)} tables using flavor='{flavor}'\")\n        return [t.df for t in tables]\n    except Exception as e:\n        print(\"Camelot failed:\", e)\n        return []\n\ntables = parse_pdf_tables(pdf_path, flavor=PARSING_FLAVOR)\nif not tables:\n    print(\"No tables found. Try setting PARSING_FLAVOR = 'lattice' and re-run the previous cells.\")\nelse:\n    # Show a preview of the first table\n    from IPython.display import display\n    display(tables[0].head() if hasattr(tables[0], \"head\") else pd.DataFrame(tables[0]).head())"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mapper"
      },
      "execution_count": null,
      "outputs": [],
      "source": "# === Step 4: Column Mapping Helper ===\n# ATR layouts can vary. We provide a heuristic mapper + quick override.\nimport re\nimport numpy as np\nimport pandas as pd\n\ndef looks_like_form(s):\n    # A crude check for form strings like \"321F6\" etc.\n    s = str(s)\n    return bool(re.search(r\"[0-9FURP\\-]+\", s, re.I)) and len(s) <= 10\n\ndef coerce_number(x):\n    try:\n        return float(str(x).strip())\n    except:\n        return np.nan\n\ndef map_columns(df):\n    # Attempt to map the raw table columns to the expected schema:\n    # name, form, trainer, age, or_rating\n    #\n    # Heuristics:\n    #   - name: the longest text-ish column (often index 2)\n    #   - form: short string with digits/F/U/R/P\n    #   - trainer: text column near the end\n    #   - age: small integer 2-12 where possible\n    #   - or_rating: 40-120 typical\n\n    df2 = df.copy()\n    df2.columns = list(range(len(df2.columns)))  # index columns numerically\n\n    # Guess candidates\n    # Name column: choose the text-heavy column with longest median length\n    name_col = max(df2.columns, key=lambda c: df2[c].astype(str).str.len().median())\n\n    # Form column: column with highest rate of \"looks_like_form\"\n    form_col = max(df2.columns, key=lambda c: df2[c].apply(looks_like_form).mean())\n\n    # Trainer column: choose a text-ish column that's not name/form and towards the right if possible\n    remaining = [c for c in df2.columns if c not in (name_col, form_col)]\n    trainer_col = max(remaining, key=lambda c: (df2[c].astype(str).str.len().median(), c))\n\n    # Age column: numeric-ish small integers\n    age_candidates = remaining.copy()\n    age_scores = {}\n    for c in age_candidates:\n        vals = pd.to_numeric(df2[c], errors=\"coerce\")\n        # proportion of values between 2 and 15 (typical ages)\n        pct = ((vals>=2) & (vals<=15)).mean()\n        age_scores[c] = pct\n    age_col = max(age_scores, key=age_scores.get)\n\n    # OR rating: numeric-ish between 40 and 120 (flat)\n    or_candidates = [c for c in remaining if c not in (trainer_col, age_col)]\n    or_scores = {}\n    for c in or_candidates:\n        vals = pd.to_numeric(df2[c], errors=\"coerce\")\n        pct = ((vals>=35) & (vals<=125)).mean()\n        or_scores[c] = pct\n    or_col = max(or_scores, key=or_scores.get) if or_scores else age_col\n\n    mapped = pd.DataFrame({\n        \"name\": df2[name_col].astype(str).str.strip(),\n        \"form\": df2[form_col].astype(str).str.strip(),\n        \"trainer\": df2[trainer_col].astype(str).str.strip(),\n        \"age\": pd.to_numeric(df2[age_col], errors=\"coerce\"),\n        \"or_rating\": pd.to_numeric(df2[or_col], errors=\"coerce\")\n    })\n\n    # Basic cleanups\n    mapped = mapped.replace({\"\": pd.NA, \"\u2014\": pd.NA, \"-\": pd.NA})\n    return mapped\n\n# Quick test mapping on first table if available\nif tables:\n    test_mapped = map_columns(tables[0])\n    from IPython.display import display\n    display(test_mapped.head())"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unity_filter"
      },
      "execution_count": null,
      "outputs": [],
      "source": "# === Step 5: Deterministic Unity Filter Wrapper ===\nimport pandas as pd\n\nclass UnityFilter:\n    def __init__(self):\n        # Minimal, deterministic example. Replace with your full logic if desired.\n        self.trainer_scores = {\n            \"aidan o'brien\": 4.0,\n            \"a p o'brien\": 4.0,\n            \"joseph patrick o'brien\": 3.8,\n            \"donnacha o'brien\": 3.5,\n            \"dermot weld\": 3.2,\n            \"jessica harrington\": 2.8,\n            \"william haggas\": 3.5,\n            \"john gosden\": 3.5,\n            \"j & t gosden\": 3.5,\n            \"charlie appleby\": 3.2,\n            \"sir michael stoute\": 3.0,\n        }\n\n    def score_runner(self, row: pd.Series) -> float:\n        score = 0.0\n        # REL-ish scoring from form string (simple and deterministic)\n        for ch in str(row.get(\"form\", \"\")):\n            if ch == \"1\": score += 3\n            elif ch == \"2\": score += 2\n            elif ch == \"3\": score += 1\n            elif ch.upper() in \"FURP\": score -= 1\n\n        # Trainer influence (optional)\n        t = str(row.get(\"trainer\", \"\")).lower().strip()\n        score += self.trainer_scores.get(t, 0)\n\n        # OR rating influence (optional)\n        try:\n            score += float(row.get(\"or_rating\", 0)) / 100.0\n        except:\n            pass\n\n        return score\n\n    def score_race(self, race_df: pd.DataFrame) -> pd.DataFrame:\n        df = race_df.copy()\n        df[\"Score\"] = df.apply(self.score_runner, axis=1)\n        return df.sort_values(\"Score\", ascending=False).reset_index(drop=True)\n\n    def top2(self, race_df: pd.DataFrame):\n        scored = self.score_race(race_df)\n        return scored.iloc[0], scored.iloc[1]\n\nuf = UnityFilter()"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_all"
      },
      "execution_count": null,
      "outputs": [],
      "source": "# === Step 6: Run on all races and print a grid ===\nimport pandas as pd\n\nresults = []\nfor i, raw in enumerate(tables, start=1):\n    try:\n        race_df = map_columns(raw)\n        # basic de-dup/cleanup: drop header-like rows by filtering non-empty names\n        race_df = race_df[race_df[\"name\"].str.len() > 0].dropna(subset=[\"name\"])\n\n        if len(race_df) < 2:\n            print(f\"Race {i}: not enough runners after mapping.\")\n            continue\n\n        top1, top2 = uf.top2(race_df)\n        results.append({\n            \"Race #\": i,\n            \"\ud83e\udd47 1st\": top1[\"name\"],\n            \"Score1\": round(float(top1[\"Score\"]), 3),\n            \"\ud83e\udd48 2nd\": top2[\"name\"],\n            \"Score2\": round(float(top2[\"Score\"]), 3),\n        })\n    except Exception as e:\n        print(f\"Race {i}: parsing/scoring issue -> {e}\")\n\ngrid = pd.DataFrame(results, columns=[\"Race #\",\"\ud83e\udd47 1st\",\"Score1\",\"\ud83e\udd48 2nd\",\"Score2\"])\nif len(grid):\n    from IPython.display import display\n    display(grid)\nelse:\n    print(\"No race results to display. Check parsing flavor or column mapping.\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n### Notes & Tweaks\n- If Camelot finds 0 tables, switch `PARSING_FLAVOR` to `\"lattice\"` in the setup cell and re-run.\n- If column mapping is wrong for a specific card, open the **Column Mapping Helper** cell and adjust the `map_columns` logic.\n- The Unity filter shown is a **minimal deterministic example**. You can replace the scoring in `score_runner` with your full Unity logic."
    }
  ]
}